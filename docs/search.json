[
  {
    "objectID": "Appendix.html",
    "href": "Appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Name - Shilpi Kumari University of Canada West 11 May , 2025"
  },
  {
    "objectID": "Appendix.html#appendix",
    "href": "Appendix.html#appendix",
    "title": "Appendix",
    "section": "Appendix",
    "text": "Appendix"
  },
  {
    "objectID": "Appendix.html#portfolio-outline---references",
    "href": "Appendix.html#portfolio-outline---references",
    "title": "Appendix",
    "section": "Portfolio Outline - References",
    "text": "Portfolio Outline - References\n\nhttps://ankitpakhale.netlify.app/portfolio\nhttps://a-coderr.github.io/portfolio-website/#home"
  },
  {
    "objectID": "Appendix.html#breif-comment-on-portfolio-sources-and-ideas",
    "href": "Appendix.html#breif-comment-on-portfolio-sources-and-ideas",
    "title": "Appendix",
    "section": "Breif Comment on Portfolio sources and ideas",
    "text": "Breif Comment on Portfolio sources and ideas\nThe LLM-generated response provided a general and foundational structure for portfolio building. Drawing from it, I emphasized my education, skills, and experiences rooted in my personal and professional background. I also expanded the portfolio by including dedicated sections on Projects and Certifications, highlighting my expertise and ongoing skill development. These additions determine the depth of my experience and also position my portfolio as a strong and competitive tool in the job market, helping it stand out from the rest."
  },
  {
    "objectID": "Appendix.html#please-find-the-link-to-the-portfolio-posted-on-github-below--",
    "href": "Appendix.html#please-find-the-link-to-the-portfolio-posted-on-github-below--",
    "title": "Appendix",
    "section": "Please find the link to the portfolio posted on GitHub below -",
    "text": "Please find the link to the portfolio posted on GitHub below -\n\nhttps://shilpi0786.github.io/Shilpi0786/"
  },
  {
    "objectID": "Appendix.html#one-page-mba-student-portfolio-outline-by-llm",
    "href": "Appendix.html#one-page-mba-student-portfolio-outline-by-llm",
    "title": "Appendix",
    "section": "One-Page MBA Student Portfolio Outline by LLM",
    "text": "One-Page MBA Student Portfolio Outline by LLM\n\nHeader\n\nName\nMBA Program & School Name\nContact Info (Email, LinkedIn, Phone, optional website or portfolio link)\n\nProfessional Summary (2‚Äì3 lines) Concise elevator pitch including industry experience, career focus, and unique strengths.\nEducation MBA Program (Include expected graduation date)\n\nRelevant coursework, GPA (if strong), academic honors\n\nKey Skills Business strategy, data analysis, financial modeling, project management, etc.\n\nSoft skills: leadership, communication, cross-functional collaboration\n\nExperience Title, Organization, Location, Dates\n\n2‚Äì3 bullet points focused on achievements and quantifiable results\nInclude pre-MBA or internship experience if relevant\n\nProjects / Leadership / Certifications Consulting projects, case competitions, club leadership, or certifications (e.g., Lean Six Sigma, AWS Certified)\nCareer Interests / Goals (Optional) 1 line on post-MBA goals or target industries/roles"
  },
  {
    "objectID": "Appendix.html#sample-one-page-mba-student-portfolio-text-only",
    "href": "Appendix.html#sample-one-page-mba-student-portfolio-text-only",
    "title": "Appendix",
    "section": "üìù Sample One-Page MBA Student Portfolio (Text Only)",
    "text": "üìù Sample One-Page MBA Student Portfolio (Text Only)\nNELSON JAMES MBA Candidate | Schulich School of Business, York University üìß nelson.james@email.com | üìû 647-555-1234 | linkedin.com/in/nelsonjames"
  },
  {
    "objectID": "Appendix.html#professional-summary",
    "href": "Appendix.html#professional-summary",
    "title": "Appendix",
    "section": "Professional Summary",
    "text": "Professional Summary\nResults-driven MBA candidate with 7+ years of experience in network security at Fortune 500 firms. Passionate about combining business acumen with cloud technology to deliver scalable, secure enterprise solutions."
  },
  {
    "objectID": "Appendix.html#education",
    "href": "Appendix.html#education",
    "title": "Appendix",
    "section": "Education",
    "text": "Education\nSchulich School of Business, York University ‚Äî Toronto, ON Master of Business Administration (MBA) | Expected: August 2025\nFocus: Technology Management & Strategy\nRelevant Coursework: Strategic Management, Cloud Computing, Data Analytics\nDean‚Äôs List (2024)"
  },
  {
    "objectID": "Appendix.html#key-skills",
    "href": "Appendix.html#key-skills",
    "title": "Appendix",
    "section": "Key Skills",
    "text": "Key Skills\nCloud Architecture ‚Ä¢ Cybersecurity Risk Management ‚Ä¢ Data Analysis (Excel, Tableau) Project Leadership ‚Ä¢ Financial Modeling ‚Ä¢ Stakeholder Communication ‚Ä¢ Agile & Scrum"
  },
  {
    "objectID": "Appendix.html#professional-experience",
    "href": "Appendix.html#professional-experience",
    "title": "Appendix",
    "section": "Professional Experience",
    "text": "Professional Experience\nSoftware Engineer ‚Äì Wipro Technologies, Toronto, ON | 2017‚Äì2023\nLed cybersecurity assessments for enterprise clients, reducing vulnerability risk by 35%.\nManaged cross-functional teams to implement security upgrades across 10+ global locations.\nDelivered client workshops on secure network practices, improving compliance scores by 20%."
  },
  {
    "objectID": "Appendix.html#leadership-certifications",
    "href": "Appendix.html#leadership-certifications",
    "title": "Appendix",
    "section": "Leadership & Certifications",
    "text": "Leadership & Certifications\nAWS Certified Solutions Architect ‚Äì Associate (2025)\nPresident, MBA Technology Club ‚Äì Organized panels with industry leaders and alumni\nTeam Lead, MBA Case Competition Finalist (Top 5 out of 120 teams)"
  },
  {
    "objectID": "Appendix.html#career-interests",
    "href": "Appendix.html#career-interests",
    "title": "Appendix",
    "section": "Career Interests",
    "text": "Career Interests\nEnterprise Cloud Security Architect | Digital Transformation Consulting | Technology Strategy"
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Shilpi Kumari Portfolio",
    "section": "üß† Skills",
    "text": "üß† Skills\nCloud & Network: AWS, EC2, Lambda, Cisco Switches & Routers, Juniper, Meraki, Firewalls (Fortigate & Palo-Alto), Cisco Meraki , Data-Centre (Nexus switches 5500,7700).\nTools & Tech: Python, SQL, Tableau, Linux , ML (for data analysis)\nSoft Skills: Project Management, Communication, Problem Solving , Multi-tasking"
  },
  {
    "objectID": "index.html#certifications",
    "href": "index.html#certifications",
    "title": "Shilpi Kumari Portfolio",
    "section": "üìú Certifications",
    "text": "üìú Certifications\n\nCCNA | Cisco Certified Network Associate\n\nCisco Meraki Black Belt\n\nAWS Cloud Practitioner\nDigital Marketing | DMI"
  },
  {
    "objectID": "index.html#connect-with-me",
    "href": "index.html#connect-with-me",
    "title": "Shilpi Kumari Portfolio",
    "section": "üåê Connect with Me",
    "text": "üåê Connect with Me\n\nLinkedIn\nInstagram\n\n\nüí¨ Prefer a pop-up?\nClick the floating button in the bottom corner instead!"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html",
    "title": "New Section",
    "section": "",
    "text": "# Loading and Exploring Social Media and Telecom Dataset\n## Explanation\nThis section connects to Google Drive and loads two datasets‚ÄîSocial Media and Telecom‚Äîinto pandas DataFrames. It allows for an initial exploration by printing the first few rows of each dataset, providing insight into the structure and types of data available.\n# Import necessary libraries\nimport pandas as pd\nfrom google.colab import drive\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# Defining file paths for both datasets\nsocialmedia_path = '/content/drive/MyDrive/socialmedia.csv'  # Update if in a specific folder\ntelecom_path = '/content/drive/MyDrive/telecom.csv'  # Update if in a specific folder\n\n# Load the social media dataset\nsocialmedia_df = pd.read_csv(socialmedia_path)\nprint(\"Social Media Dataset:\")\nprint(socialmedia_df.head())  # Display the first few rows\n\n# Load the telecom dataset\ntelecom_df = pd.read_csv(telecom_path)\nprint(\"\\nTelecom Dataset:\")\nprint(telecom_df.head())  # Display the first few rows\n\n\n\n\n\n\nMounted at /content/drive\nSocial Media Dataset:\n   Page total likes    Type  Category  Post Month  Post Weekday  Post Hour  \\\n0            139441   Photo         2          12             4          3   \n1            139441  Status         2          12             3         10   \n2            139441   Photo         3          12             3          3   \n3            139441   Photo         2          12             2         10   \n4            139441   Photo         2          12             2          3   \n\n   Paid  Lifetime Post Total Reach  Lifetime Post Total Impressions  \\\n0   0.0                       2752                             5091   \n1   0.0                      10460                            19057   \n2   0.0                       2413                             4373   \n3   1.0                      50128                            87991   \n4   0.0                       7244                            13594   \n\n   Lifetime Engaged Users  Lifetime Post Consumers  \\\n0                     178                      109   \n1                    1457                     1361   \n2                     177                      113   \n3                    2211                      790   \n4                     671                      410   \n\n   Lifetime Post Consumptions  \\\n0                         159   \n1                        1674   \n2                         154   \n3                        1119   \n4                         580   \n\n   Lifetime Post Impressions by people who have liked your Page  \\\n0                                               3078              \n1                                              11710              \n2                                               2812              \n3                                              61027              \n4                                               6228              \n\n   Lifetime Post reach by people who like your Page  \\\n0                                              1640   \n1                                              6112   \n2                                              1503   \n3                                             32048   \n4                                              3200   \n\n   Lifetime People who have liked your Page and engaged with your post  \\\n0                                                119                     \n1                                               1108                     \n2                                                132                     \n3                                               1386                     \n4                                                396                     \n\n   comment    like  share  Total Interactions  \n0        4    79.0   17.0                 100  \n1        5   130.0   29.0                 164  \n2        0    66.0   14.0                  80  \n3       58  1572.0  147.0                1777  \n4       19   325.0   49.0                 393  \n\nTelecom Dataset:\n   Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n0              8          0                    38               0   \n1              0          0                    39               0   \n2             10          0                    37               0   \n3             10          0                    38               0   \n4              3          0                    38               0   \n\n   Seconds of Use  Frequency of use  Frequency of SMS  \\\n0            4370                71                 5   \n1             318                 5                 7   \n2            2453                60               359   \n3            4198                66                 1   \n4            2393                58                 2   \n\n   Distinct Called Numbers  Age Group  Tariff Plan  Status  Age  \\\n0                       17          3            1       1   30   \n1                        4          2            1       2   25   \n2                       24          3            1       1   30   \n3                       35          1            1       1   15   \n4                       33          1            1       1   15   \n\n   Customer Value  Churn  \n0         197.640      0  \n1          46.035      0  \n2        1536.520      0  \n3         240.020      0  \n4         145.805      0"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation",
    "title": "New Section",
    "section": "Explanation",
    "text": "Explanation\nThis section focuses on the data cleaning necessary for preparing the Social Media Metrics dataset for machine learning. It includes selecting relevant input features and the target variable, handling missing values, and previewing the cleaned dataset. These steps are essential before applying any modelling techniques.\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# Load the Social Media Metrics dataset\nsocialmedia_df = pd.read_csv('/content/drive/MyDrive/socialmedia.csv')\n\n# Selecting relevant features and target variable\nfeatures = ['Page total likes', 'Type', 'Category', 'Post Hour', 'Paid']\nX_socialmedia = socialmedia_df[features]\ny_socialmedia = socialmedia_df['Lifetime Engaged Users']\n\n# Handling missing values\nX_socialmedia = X_socialmedia.fillna(0)  # Replace with more appropriate imputation if needed\n\n# Display dataset structure\nprint(\"Features dataset:\")\nprint(X_socialmedia.head())\nprint(\"\\nTarget variable:\")\nprint(y_socialmedia.head())"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-1",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-1",
    "title": "New Section",
    "section": "Explanation",
    "text": "Explanation\nThis section defines the preprocessing steps and creates a machine learning pipeline for predicting user engagement (Lifetime Engaged Users) using a linear regression model. It also prepares the data for training and testing by splitting it into subsets.\n\n# Define the preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), ['Page total likes', 'Post Hour', 'Paid']),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Type', 'Category'])\n    ])\n\n# Define the pipeline\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', LinearRegression())\n])\n\n# Split the data into training and testing sets (80-20 split)\nX_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_socialmedia, y_socialmedia, test_size=0.2, random_state=42)"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-2",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-2",
    "title": "New Section",
    "section": "Explanation",
    "text": "Explanation\nThis section completes the regression modeling process by training the pipeline, generating predictions, and evaluating performance on both training and test datasets. This helps assess how well the model generalizes to new, unseen data.\n\n# Fit the model on training data\npipeline.fit(X_train_sm, y_train_sm)\n\n# Make predictions on both training and testing data\ny_train_pred_sm = pipeline.predict(X_train_sm)\ny_test_pred_sm = pipeline.predict(X_test_sm)\n\n# Evaluate the model\ntrain_mse_sm = mean_squared_error(y_train_sm, y_train_pred_sm)\ntest_mse_sm = mean_squared_error(y_test_sm, y_test_pred_sm)\ntrain_r2_sm = r2_score(y_train_sm, y_train_pred_sm)\ntest_r2_sm = r2_score(y_test_sm, y_test_pred_sm)\n\nprint(f\"Training MSE: {train_mse_sm}, Training R¬≤: {train_r2_sm}\")\nprint(f\"Testing MSE: {test_mse_sm}, Testing R¬≤: {test_r2_sm}\")\n\nTraining MSE: 851154.5821688741, Training R¬≤: 0.20570089686390247\nTesting MSE: 459291.161656748, Testing R¬≤: 0.1558370513520827"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-3",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-3",
    "title": "New Section",
    "section": "Explanation",
    "text": "Explanation\nThis section extracts and displays the importance of each feature in the regression model by analyzing the coefficients assigned during training. It provides insight into which variables most significantly affect predicted user engagement.\n\n# Get feature names after encoding\nfeature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(['Type', 'Category'])\nall_feature_names = ['Page total likes', 'Post Hour', 'Paid'] + list(feature_names)\n\n# Model coefficients\ncoefficients = pipeline.named_steps['regressor'].coef_\n\n# Display feature importance\nfeature_importance = pd.DataFrame({'Feature': all_feature_names, 'Coefficient': coefficients})\nfeature_importance = feature_importance.sort_values(by='Coefficient', key=abs, ascending=False)\nprint(\"\\nFeature Importance (sorted by absolute coefficient values):\")\nprint(feature_importance)\n\n\n\nFeature Importance (sorted by absolute coefficient values):\n            Feature  Coefficient\n3         Type_Link -1131.852370\n5       Type_Status   994.154893\n6        Type_Video   652.484424\n4        Type_Photo  -514.786947\n0  Page total likes  -231.231917\n2              Paid   132.694985\n7        Category_1    63.564900\n1         Post Hour   -56.536562\n8        Category_2   -33.876303\n9        Category_3   -29.688597"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-4",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-4",
    "title": "New Section",
    "section": "Explanation",
    "text": "Explanation\nThis section loads the Telecom Churn dataset and performs an initial data inspection to prepare for churn prediction. It identifies the target variable (Churn) and separates it from the feature set (X_telecom), setting the stage for future preprocessing and model building.\n\nimport pandas as pd\n\n# Load the churn dataset (make sure the path is correct)\ntelecom_df = pd.read_csv('/content/drive/MyDrive/telecom.csv')\n\n# Check the first few rows of the dataset to confirm it loaded correctly\nprint(\"Dataset Sample:\")\nprint(telecom_df.head())\n\n# Define the target variable 'Churn' and separate features\nX_telecom = telecom_df.drop(columns=['Churn'], errors='ignore')\ny_telecom = telecom_df['Churn']\n\n# Verify column names and structure of the data\nprint(\"\\nFeature Columns:\")\nprint(X_telecom.columns)\nprint(\"\\nTarget Variable Sample:\")\nprint(y_telecom.head())\n\nDataset Sample:\n   Call  Failure  Complains  Subscription  Length  Charge  Amount  \\\n0              8          0                    38               0   \n1              0          0                    39               0   \n2             10          0                    37               0   \n3             10          0                    38               0   \n4              3          0                    38               0   \n\n   Seconds of Use  Frequency of use  Frequency of SMS  \\\n0            4370                71                 5   \n1             318                 5                 7   \n2            2453                60               359   \n3            4198                66                 1   \n4            2393                58                 2   \n\n   Distinct Called Numbers  Age Group  Tariff Plan  Status  Age  \\\n0                       17          3            1       1   30   \n1                        4          2            1       2   25   \n2                       24          3            1       1   30   \n3                       35          1            1       1   15   \n4                       33          1            1       1   15   \n\n   Customer Value  Churn  \n0         197.640      0  \n1          46.035      0  \n2        1536.520      0  \n3         240.020      0  \n4         145.805      0  \n\nFeature Columns:\nIndex(['Call  Failure', 'Complains', 'Subscription  Length', 'Charge  Amount',\n       'Seconds of Use', 'Frequency of use', 'Frequency of SMS',\n       'Distinct Called Numbers', 'Age Group', 'Tariff Plan', 'Status', 'Age',\n       'Customer Value'],\n      dtype='object')\n\nTarget Variable Sample:\n0    0\n1    0\n2    0\n3    0\n4    0\nName: Churn, dtype: int64"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-5",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#explanation-5",
    "title": "New Section",
    "section": "Explanation",
    "text": "Explanation\n\nData Preparation and Cleaning\nThe telecom dataset was loaded from Google Drive and inspected for missing values.\nMissing data was handled by dropping rows with null entries to ensure the dataset was clean and complete before modeling.\n\n\nFeature Selection and Separation\nThe target variable is ‚ÄòChurn‚Äô, indicating whether a customer left the service.\nAll remaining columns were treated as input features, further divided into:\nNumerical features (e.g., age, usage metrics)\nCategorical features (Age Group, Tariff Plan, Status)\n\n\nPreprocessing Pipeline\nTo prepare the data for modeling:\nNumerical features were standardized using StandardScaler to ensure all values are on a similar scale.\nCategorical features were encoded using OneHotEncoder, converting categories into a machine-readable numeric format.\nA ColumnTransformer combined these preprocessing steps, and each model was embedded in a pipeline to ensure consistent processing.\n\n\nModel Training and Evaluation\nThe dataset was split into training (80%) and testing (20%) sets.\n\nTwo models were trained:\nLogistic Regression: A linear classifier suitable for binary classification and interpreting feature importance.\nK-Nearest Neighbors (KNN): A distance-based classifier that predicts labels based on the nearest data points in the feature space.\nEach model was evaluated using accuracy score on the test set, providing an initial measure of predictive performance.\n\n\n\nHyperparameter Tuning for KNN\nSince KNN‚Äôs performance depends heavily on the choice of K (number of neighbors), a loop tested values of K from 1 to 20.\nThe accuracy for each K was recorded and visualized using a line plot.\nThe optimal K was identified ‚Äî the one that achieved the highest test accuracy.\n\n\nFeature Importance Analysis (Logistic Regression)\nCoefficients from the logistic regression model were extracted to assess the impact of each feature on churn.\nPositive coefficients indicate features that increase the likelihood of churn.\nNegative coefficients indicate features that decrease the likelihood.\nThis insight helps stakeholders understand which variables are most critical in predicting customer behavior.\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ntelecom_path = '/content/drive/MyDrive/telecom.csv'  # Update if in a specific folder\ntelecom_df = pd.read_csv(telecom_path)\n\n\n# Check for missing values\nprint(\"Missing Values:\", telecom_df.isnull().sum())\n\n# Handle missing values (for simplicity, we'll drop rows with missing values)\ntelecom_df = telecom_df.dropna()\n\n# Define feature columns and target variable\nX_telecom = telecom_df.drop('Churn', axis=1)  # Features\ny_telecom = telecom_df['Churn']  # Target\n\n# Separate categorical and numerical features\ncategorical_features = ['Age Group', 'Tariff Plan', 'Status']  # Example of categorical features\nnumerical_features = X_telecom.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\n# Preprocessing pipeline for numerical and categorical features\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_features),  # Scale numerical features\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  # Encode categorical features\n    ])\n\n# Create a pipeline for Logistic Regression and KNN models\nlogreg_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression())\n])\n\nknn_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', KNeighborsClassifier())\n])\n\n# Split data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X_telecom, y_telecom, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nlogreg_pipeline.fit(X_train, y_train)\n\n# Train KNN model (with K=5)\nknn_pipeline.fit(X_train, y_train)\n\n# Predictions\nlogreg_preds = logreg_pipeline.predict(X_test)\nknn_preds = knn_pipeline.predict(X_test)\n\n# Evaluate models using accuracy\nlogreg_accuracy = accuracy_score(y_test, logreg_preds)\nknn_accuracy = accuracy_score(y_test, knn_preds)\n\nprint(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\nprint(f\"KNN Accuracy (K=5): {knn_accuracy}\")\n\n# Explore effect of changing K in KNN\nk_values = range(1, 21)  # Test K values from 1 to 20\nknn_accuracies = []\n\nfor k in k_values:\n    knn_pipeline.set_params(classifier=KNeighborsClassifier(n_neighbors=k))\n    knn_pipeline.fit(X_train, y_train)\n    knn_preds = knn_pipeline.predict(X_test)\n    knn_accuracies.append(accuracy_score(y_test, knn_preds))\n\n# Plot accuracy vs K\nplt.plot(k_values, knn_accuracies, marker='o')\nplt.title('KNN Accuracy vs K')\nplt.xlabel('K (Number of Neighbors)')\nplt.ylabel('Accuracy')\nplt.show()\n\n# Best K\nbest_k = k_values[knn_accuracies.index(max(knn_accuracies))]\nprint(f\"Best K for KNN: {best_k}\")\n\n# Analysis: Most important features based on model coefficients (Logistic Regression)\nlogreg_coef = logreg_pipeline.named_steps['classifier'].coef_[0]\nfeature_names = numerical_features + list(preprocessor.transformers_[1][1].get_feature_names_out(categorical_features))\nfeature_importance = pd.DataFrame({'Feature': feature_names, 'Coefficient': logreg_coef})\nprint(feature_importance.sort_values(by='Coefficient', ascending=False))\n\nMissing Values: Call  Failure              0\nComplains                  0\nSubscription  Length       0\nCharge  Amount             0\nSeconds of Use             0\nFrequency of use           0\nFrequency of SMS           0\nDistinct Called Numbers    0\nAge Group                  0\nTariff Plan                0\nStatus                     0\nAge                        0\nCustomer Value             0\nChurn                      0\ndtype: int64\nLogistic Regression Accuracy: 0.8698412698412699\nKNN Accuracy (K=5): 0.9317460317460318\n\n\n\n\n\n\n\n\n\nBest K for KNN: 2\n                    Feature  Coefficient\n1                 Complains     1.103923\n0             Call  Failure     0.868096\n4            Seconds of Use     0.865874\n14              Age Group_2     0.695437\n16              Age Group_4     0.675648\n15              Age Group_3     0.533240\n10                   Status     0.351586\n12           Customer Value     0.192794\n8                 Age Group     0.149933\n21                 Status_2     0.148200\n9               Tariff Plan     0.137933\n19            Tariff Plan_2     0.036391\n18            Tariff Plan_1    -0.046620\n11                      Age    -0.154419\n20                 Status_1    -0.158429\n2      Subscription  Length    -0.175953\n7   Distinct Called Numbers    -0.365365\n3            Charge  Amount    -0.629595\n17              Age Group_5    -0.918529\n13              Age Group_1    -0.996025\n6          Frequency of SMS    -1.728051\n5          Frequency of use    -2.192656"
  },
  {
    "objectID": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#model-performance-summary",
    "href": "projects/Customer_Churn_Analysis_using_KNN_and_Logistic_Regression.html#model-performance-summary",
    "title": "New Section",
    "section": "Model Performance Summary",
    "text": "Model Performance Summary\nAfter preprocessing and training both models on the telecom dataset, the following results were observed:\n\nLogistic Regression Accuracy: 86.98%\n\n\nK-Nearest Neighbors (K=5) Accuracy: 93.17%\nOptimal K for KNN: 2 yielded the highest accuracy among the tested values (1‚Äì20).\nThese results indicate that KNN outperformed Logistic Regression in terms of predictive accuracy, making it the stronger model for identifying churn risk in this dataset."
  },
  {
    "objectID": "Contact.html",
    "href": "Contact.html",
    "title": "Contact Me",
    "section": "",
    "text": "I‚Äôd love to hear from you! Whether it‚Äôs a question, collaboration opportunity, or feedback ‚Äî feel free to reach out through any of the channels below.\n\n\n\n+1 (778) 990-2716\n\n\n\n\nkr.shilpi21@gmail.com\n\n\n\n\nConnect with me on LinkedIn\n\n\n\n\nVisit my Portfolio\n\n\n\n\n20686 , Eastleigh Crescent , Langley , V3A0M4 , BC.\n\n\n\n\n\n Your Email:  \n Your Message: \n\n\nSend\n\n\n\nüîí Your privacy is important. Your contact info will never be shared."
  },
  {
    "objectID": "Contact.html#phone-whatsapp",
    "href": "Contact.html#phone-whatsapp",
    "title": "Contact Me",
    "section": "",
    "text": "+1 (778) 990-2716"
  },
  {
    "objectID": "Contact.html#email",
    "href": "Contact.html#email",
    "title": "Contact Me",
    "section": "",
    "text": "kr.shilpi21@gmail.com"
  },
  {
    "objectID": "Contact.html#linkedin",
    "href": "Contact.html#linkedin",
    "title": "Contact Me",
    "section": "",
    "text": "Connect with me on LinkedIn"
  },
  {
    "objectID": "Contact.html#portfolio",
    "href": "Contact.html#portfolio",
    "title": "Contact Me",
    "section": "",
    "text": "Visit my Portfolio"
  },
  {
    "objectID": "Contact.html#location",
    "href": "Contact.html#location",
    "title": "Contact Me",
    "section": "",
    "text": "20686 , Eastleigh Crescent , Langley , V3A0M4 , BC."
  },
  {
    "objectID": "Contact.html#contact-me-1",
    "href": "Contact.html#contact-me-1",
    "title": "Contact Me",
    "section": "",
    "text": "Your Email:  \n Your Message: \n\n\nSend\n\n\n\nüîí Your privacy is important. Your contact info will never be shared."
  },
  {
    "objectID": "sss.html",
    "href": "sss.html",
    "title": "Resume | Shilpi Kumari",
    "section": "",
    "text": "Hi, I‚Äôm Shilpi Kumari\n\n\nCloud Engineer | Network Analyst | MBA Candidate\n\n\n\n\n\nüéì Education\n\n\n\nMBA ‚Äì University Canada West (Expected June 2025)\n\n\nBCA ‚Äì Patna University\n\n\n\n\n\n\nüß† Skills\n\n\n&lt;div&gt;\n  &lt;h3&gt;Cloud & Networking&lt;/h3&gt;\n  &lt;ul&gt;\n    &lt;li&gt;AWS, EC2, Lambda&lt;/li&gt;\n    &lt;li&gt;Cisco, Juniper, Meraki&lt;/li&gt;\n    &lt;li&gt;Switching & Routing (OSPF, BGP, EIGRP)&lt;/li&gt;\n    &lt;li&gt;Firewalls: Fortigate, Palo-Alto&lt;/li&gt;\n    &lt;li&gt;Nexus Switches 5500/7700&lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/div&gt;\n&lt;div&gt;\n  &lt;h3&gt;Tools & Soft Skills&lt;/h3&gt;\n  &lt;ul&gt;\n    &lt;li&gt;Python, SQL, Linux, Tableau, ML&lt;/li&gt;\n    &lt;li&gt;Project Management&lt;/li&gt;\n    &lt;li&gt;Problem Solving & Communication&lt;/li&gt;\n    &lt;li&gt;Multitasking & Team Collaboration&lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/div&gt;\n\n\n\n\n\nüìú Certifications\n\n\n\nCCNA ‚Äì Cisco Certified Network Associate\n\n\nCisco Meraki Black Belt\n\n\nAWS Cloud Practitioner\n\n\nDMI ‚Äì Digital Marketing Institute\n\n\n\n\n\nüìÑ Download Resume (PDF)\n\n\n\n\nConnect: LinkedIn | Instagram\n\n\n¬© 2025 Shilpi Kumari | All Rights Reserved"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "üìÑ Download My Resume (PDF)\n\n\nExperienced Network Administrator with over 7 years of experience managing enterprise LAN/WAN operations and multi-vendor device configurations. Demonstrated expertise in implementing robust firewall policies and conducting vulnerability assessments to enhance network security. Successfully collaborated on fibre network projects and optimized workflows for improved operational efficiency. Eager to leverage comprehensive technical skills in routing, switching, and cloud networking to support and advance IT infrastructure environments.\n\n\n\n\n\n\nDesigned and deployed scalable cloud solutions across AWS for enterprise clients in telecom and retail,resulting in 20% improvement in application performance/cost savings.\nManaged hybrid client network solutions of multi-vendor environments(Cisco, Juniper, FortiGate, F5),ensuring 95% network uptime and resolving critical issues within critical 4 hours timeframe.‚Äù\nMentored new hires, managed multi-client SLAs ,consistently achieving 99% SLA adherence and improving team efficiency by 20%.‚Äù\n\n\n\n\n\nPartnered with cross-functional teams to conduct thorough discovery and implementation of fibre networks to sites,successfully connecting 15 number of sites within 2 months timeframe.‚Äù\nIdentified and resolved process issues to drive optimal workflow and business growth,resulting in 15% improvement in process efficiency/cost savings.\nDeveloped SOPs and resolved telecom operations ,reducing issue resolution time by 25%.‚Äù\n\n\n\n\n\nManaged LAN/WAN infrastructure and executed scheduled patching of routers, firewalls, and switches, reducing security vulnerabilities by 10% and ensuring 95% system uptime.‚Äù\nConfigure and onbarded new switches and router on clinet demands for new site extensions and support,completing an average of 2 new site setups per month/quarter.‚Äù\n\n\n\n\n\nMBA, University Canada West\nExpected: 2025\nBachelor‚Äôs Degree, [Bachelors of Computer Application], [Patna University]\nGraduated: [2015]\n\n\n\nCloud & Network: AWS, EC2, Lambda, Cisco Switches & Routers, Juniper, Meraki, Firewalls (Fortigate & Palo-Alto), Cisco Meraki , Data-Centre (Nexus switches 5500,7700).\nTools & Tech: Python, SQL, Tableau, Linux , ML (for data analysis)\nSoft Skills: Project Management, Communication, Problem Solving , Multi-tasking\n\n\n\n\nCCNA | Cisco Certified Network Associate\n\nCisco Meraki Black Belt\n\nAWS Cloud Practitioner\nDigital Marketing\n\n\n\n\n\nEnglish (ADVANCED)\nHINDI (Proficient)\n\n\n\n\n-Volunteer Coordinator, Local Community Center - Assisted with event planning and community outreach to support local engagement."
  },
  {
    "objectID": "resume.html#professional-summary",
    "href": "resume.html#professional-summary",
    "title": "Resume",
    "section": "",
    "text": "Experienced Network Administrator with over 7 years of experience managing enterprise LAN/WAN operations and multi-vendor device configurations. Demonstrated expertise in implementing robust firewall policies and conducting vulnerability assessments to enhance network security. Successfully collaborated on fibre network projects and optimized workflows for improved operational efficiency. Eager to leverage comprehensive technical skills in routing, switching, and cloud networking to support and advance IT infrastructure environments."
  },
  {
    "objectID": "resume.html#experience",
    "href": "resume.html#experience",
    "title": "Resume",
    "section": "",
    "text": "Designed and deployed scalable cloud solutions across AWS for enterprise clients in telecom and retail,resulting in 20% improvement in application performance/cost savings.\nManaged hybrid client network solutions of multi-vendor environments(Cisco, Juniper, FortiGate, F5),ensuring 95% network uptime and resolving critical issues within critical 4 hours timeframe.‚Äù\nMentored new hires, managed multi-client SLAs ,consistently achieving 99% SLA adherence and improving team efficiency by 20%.‚Äù\n\n\n\n\n\nPartnered with cross-functional teams to conduct thorough discovery and implementation of fibre networks to sites,successfully connecting 15 number of sites within 2 months timeframe.‚Äù\nIdentified and resolved process issues to drive optimal workflow and business growth,resulting in 15% improvement in process efficiency/cost savings.\nDeveloped SOPs and resolved telecom operations ,reducing issue resolution time by 25%.‚Äù\n\n\n\n\n\nManaged LAN/WAN infrastructure and executed scheduled patching of routers, firewalls, and switches, reducing security vulnerabilities by 10% and ensuring 95% system uptime.‚Äù\nConfigure and onbarded new switches and router on clinet demands for new site extensions and support,completing an average of 2 new site setups per month/quarter.‚Äù"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "",
    "text": "MBA, University Canada West\nExpected: 2025\nBachelor‚Äôs Degree, [Bachelors of Computer Application], [Patna University]\nGraduated: [2015]"
  },
  {
    "objectID": "resume.html#skills",
    "href": "resume.html#skills",
    "title": "Resume",
    "section": "",
    "text": "Cloud & Network: AWS, EC2, Lambda, Cisco Switches & Routers, Juniper, Meraki, Firewalls (Fortigate & Palo-Alto), Cisco Meraki , Data-Centre (Nexus switches 5500,7700).\nTools & Tech: Python, SQL, Tableau, Linux , ML (for data analysis)\nSoft Skills: Project Management, Communication, Problem Solving , Multi-tasking"
  },
  {
    "objectID": "resume.html#certifications",
    "href": "resume.html#certifications",
    "title": "Resume",
    "section": "",
    "text": "CCNA | Cisco Certified Network Associate\n\nCisco Meraki Black Belt\n\nAWS Cloud Practitioner\nDigital Marketing"
  },
  {
    "objectID": "resume.html#languages",
    "href": "resume.html#languages",
    "title": "Resume",
    "section": "",
    "text": "English (ADVANCED)\nHINDI (Proficient)"
  },
  {
    "objectID": "resume.html#volunteer-experience",
    "href": "resume.html#volunteer-experience",
    "title": "Resume",
    "section": "",
    "text": "-Volunteer Coordinator, Local Community Center - Assisted with event planning and community outreach to support local engagement."
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Projects",
    "section": "",
    "text": "Course: Organizational Diagnosis\nTools Used: PESTELE, SWOT, Stakeholder Analysis Outcome: Proposed a strategic framework to enhance host engagement and brand visibility.\n\n\n\nRole: Project Manager\nWork: Built a Work Breakdown Structure and timeline for a cold-pressed organic juice launch.\nResult: Proposed cross-channel strategies including events, digital ads, and loyalty programs.\n\n\n\n\n\nDescription: A serverless personal resume website deployed on AWS using S3 for hosting, Lambda for potential dynamic features, API Gateway for external interactions, and DynamoDB for data storage.\nTools: Deployment using AWS S3, Lambda, API Gateway, DynamoDB\n\nDetailed explanation in this file * link\n\n\n\n\nDescription: An AWS infrastructure setup for hosting a tour planning web application, leveraging EC2 for compute, RDS for database management, VPC for network isolation, and Security Groups for access control.\nTools: EC2, RDS, VPC, Security Groups\n\nDetailed explanation of configuation and deployment attached in file -\nPart 1\nPart 2\n\n\n\n\nA data analysis project using Python and machine learning models (KNN and Logistic Regression) to analyze customer data and predict churn probability.\nTools: Google Colab, Python, Scikit-learn (KNN, Logistic Regression), Pandas, NumPy"
  },
  {
    "objectID": "Projects.html#popin-event-host-collaboration-strategy",
    "href": "Projects.html#popin-event-host-collaboration-strategy",
    "title": "Projects",
    "section": "",
    "text": "Course: Organizational Diagnosis\nTools Used: PESTELE, SWOT, Stakeholder Analysis Outcome: Proposed a strategic framework to enhance host engagement and brand visibility."
  },
  {
    "objectID": "Projects.html#unsweetened-juice-product-launch",
    "href": "Projects.html#unsweetened-juice-product-launch",
    "title": "Projects",
    "section": "",
    "text": "Role: Project Manager\nWork: Built a Work Breakdown Structure and timeline for a cold-pressed organic juice launch.\nResult: Proposed cross-channel strategies including events, digital ads, and loyalty programs."
  },
  {
    "objectID": "Projects.html#technical-projects",
    "href": "Projects.html#technical-projects",
    "title": "Projects",
    "section": "",
    "text": "Description: A serverless personal resume website deployed on AWS using S3 for hosting, Lambda for potential dynamic features, API Gateway for external interactions, and DynamoDB for data storage.\nTools: Deployment using AWS S3, Lambda, API Gateway, DynamoDB\n\nDetailed explanation in this file * link\n\n\n\n\nDescription: An AWS infrastructure setup for hosting a tour planning web application, leveraging EC2 for compute, RDS for database management, VPC for network isolation, and Security Groups for access control.\nTools: EC2, RDS, VPC, Security Groups\n\nDetailed explanation of configuation and deployment attached in file -\nPart 1\nPart 2\n\n\n\n\nA data analysis project using Python and machine learning models (KNN and Logistic Regression) to analyze customer data and predict churn probability.\nTools: Google Colab, Python, Scikit-learn (KNN, Logistic Regression), Pandas, NumPy"
  },
  {
    "objectID": "Skills.html",
    "href": "Skills.html",
    "title": "Skills & Certifications",
    "section": "",
    "text": "Cloud Platforms: AWS (EC2, Lambda), Cisco Meraki\nNetworking Devices: Cisco Switches & Routers, Juniper, Nexus Switches (5500, 7700)\nSwitching Concepts: VLANs, STP (Spanning Tree Protocol), EtherChannel, VTP\nRouting Protocols: OSPF, EIGRP, BGP, Static Routing\nFirewall Technologies\n\nFortiGate (policy-based & profile-based rules)\nPalo Alto (App-ID, NAT, Zone-based security)\nCisco ASA & Meraki Firewalls\n\n\n\n\n\n\nProgramming: Python\nDatabase: SQL\nData Visualization: Tableau\nOperating Systems: Linux (Bash, system administration)\nMachine Learning: Applied ML for data analysis"
  },
  {
    "objectID": "Skills.html#cloud-networking",
    "href": "Skills.html#cloud-networking",
    "title": "Skills & Certifications",
    "section": "",
    "text": "Cloud Platforms: AWS (EC2, Lambda), Cisco Meraki\nNetworking Devices: Cisco Switches & Routers, Juniper, Nexus Switches (5500, 7700)\nSwitching Concepts: VLANs, STP (Spanning Tree Protocol), EtherChannel, VTP\nRouting Protocols: OSPF, EIGRP, BGP, Static Routing\nFirewall Technologies\n\nFortiGate (policy-based & profile-based rules)\nPalo Alto (App-ID, NAT, Zone-based security)\nCisco ASA & Meraki Firewalls"
  },
  {
    "objectID": "Skills.html#tools-technologies",
    "href": "Skills.html#tools-technologies",
    "title": "Skills & Certifications",
    "section": "",
    "text": "Programming: Python\nDatabase: SQL\nData Visualization: Tableau\nOperating Systems: Linux (Bash, system administration)\nMachine Learning: Applied ML for data analysis"
  }
]